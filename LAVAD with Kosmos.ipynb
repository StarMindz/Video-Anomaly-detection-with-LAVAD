{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "05a0a23b-f2af-445d-aec5-c968bcdc5f95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting opencv-python-headless\n",
      "  Downloading opencv_python_headless-4.10.0.84-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (49.9 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.9/49.9 MB\u001b[0m \u001b[31m37.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy in /usr/lib/python3/dist-packages (1.21.5)\n",
      "Collecting transformers\n",
      "  Downloading transformers-4.46.2-py3-none-any.whl (10.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.0/10.0 MB\u001b[0m \u001b[31m98.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting sentence-transformers\n",
      "  Downloading sentence_transformers-3.3.0-py3-none-any.whl (268 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.7/268.7 KB\u001b[0m \u001b[31m46.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: torch in /usr/lib/python3/dist-packages (2.3.1)\n",
      "Collecting regex!=2019.12.17\n",
      "  Downloading regex-2024.11.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (781 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m781.7/781.7 KB\u001b[0m \u001b[31m79.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting tokenizers<0.21,>=0.20\n",
      "  Downloading tokenizers-0.20.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m122.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: filelock in /usr/lib/python3/dist-packages (from transformers) (3.6.0)\n",
      "Collecting tqdm>=4.27\n",
      "  Downloading tqdm-4.67.0-py3-none-any.whl (78 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.6/78.6 KB\u001b[0m \u001b[31m18.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting huggingface-hub<1.0,>=0.23.2\n",
      "  Downloading huggingface_hub-0.26.2-py3-none-any.whl (447 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m447.5/447.5 KB\u001b[0m \u001b[31m56.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/lib/python3/dist-packages (from transformers) (21.3)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/lib/python3/dist-packages (from transformers) (5.4.1)\n",
      "Collecting safetensors>=0.4.1\n",
      "  Downloading safetensors-0.4.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (435 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m435.0/435.0 KB\u001b[0m \u001b[31m66.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: requests in /usr/lib/python3/dist-packages (from transformers) (2.25.1)\n",
      "Requirement already satisfied: scikit-learn in /usr/lib/python3/dist-packages (from sentence-transformers) (0.23.2)\n",
      "Requirement already satisfied: Pillow in /usr/lib/python3/dist-packages (from sentence-transformers) (9.0.1)\n",
      "Requirement already satisfied: scipy in /usr/lib/python3/dist-packages (from sentence-transformers) (1.8.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/lib/python3/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.3.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/lib/python3/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.9.0)\n",
      "Installing collected packages: tqdm, safetensors, regex, opencv-python-headless, huggingface-hub, tokenizers, transformers, sentence-transformers\n",
      "Successfully installed huggingface-hub-0.26.2 opencv-python-headless-4.10.0.84 regex-2024.11.6 safetensors-0.4.5 sentence-transformers-3.3.0 tokenizers-0.20.3 tqdm-4.67.0 transformers-4.46.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install opencv-python-headless numpy transformers sentence-transformers torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4aacc5a2-37a3-4ab6-abe2-20d30afa8f8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting faiss-gpu\n",
      "  Downloading faiss_gpu-1.7.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (85.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.5/85.5 MB\u001b[0m \u001b[31m22.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting bitsandbytes\n",
      "  Downloading bitsandbytes-0.44.1-py3-none-manylinux_2_24_x86_64.whl (122.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m122.4/122.4 MB\u001b[0m \u001b[31m17.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting accelerate\n",
      "  Downloading accelerate-1.1.1-py3-none-any.whl (333 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m333.2/333.2 KB\u001b[0m \u001b[31m51.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: torch in /usr/lib/python3/dist-packages (from bitsandbytes) (2.3.1)\n",
      "Requirement already satisfied: numpy in /usr/lib/python3/dist-packages (from bitsandbytes) (1.21.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/lib/python3/dist-packages (from accelerate) (21.3)\n",
      "Requirement already satisfied: psutil in /usr/lib/python3/dist-packages (from accelerate) (5.9.0)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in ./.local/lib/python3.10/site-packages (from accelerate) (0.4.5)\n",
      "Requirement already satisfied: huggingface-hub>=0.21.0 in ./.local/lib/python3.10/site-packages (from accelerate) (0.26.2)\n",
      "Requirement already satisfied: pyyaml in /usr/lib/python3/dist-packages (from accelerate) (5.4.1)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in ./.local/lib/python3.10/site-packages (from huggingface-hub>=0.21.0->accelerate) (4.67.0)\n",
      "Requirement already satisfied: filelock in /usr/lib/python3/dist-packages (from huggingface-hub>=0.21.0->accelerate) (3.6.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/lib/python3/dist-packages (from huggingface-hub>=0.21.0->accelerate) (4.9.0)\n",
      "Requirement already satisfied: requests in /usr/lib/python3/dist-packages (from huggingface-hub>=0.21.0->accelerate) (2.25.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/lib/python3/dist-packages (from huggingface-hub>=0.21.0->accelerate) (2024.3.1)\n",
      "Installing collected packages: faiss-gpu, bitsandbytes, accelerate\n",
      "Successfully installed accelerate-1.1.1 bitsandbytes-0.44.1 faiss-gpu-1.7.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install faiss-gpu bitsandbytes accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bacc45c9-b55d-456b-bf72-ecc85f427408",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install huggingface_hub==0.15.1 transformers==4.31.0 sentence-transformers==2.2.2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "083a896c-f975-4505-8a42-a3073c383070",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "from transformers import AutoProcessor, AutoModelForImageTextToText, AutoTokenizer, AutoModel\n",
    "# from sentence_transformers import SentenceTransformer, util\n",
    "import faiss\n",
    "from pathlib import Path\n",
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7ebe85cc-3d57-4ecc-b554-2f9db74ad76a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.cuda.memory_allocated())\n",
    "print(torch.cuda.memory_reserved())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6794b276-0391-4a01-835a-ce46ec5c413f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize models\n",
    "model = 'microsoft/kosmos-2-patch14-224'\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "caption_processor = AutoProcessor.from_pretrained(model)\n",
    "caption_model = AutoModelForImageTextToText.from_pretrained(model).to(device)\n",
    "\n",
    "\n",
    "# Initialize Hugging Face model for sentence embeddings\n",
    "embedding_model_name = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "embedding_tokenizer = AutoTokenizer.from_pretrained(embedding_model_name)\n",
    "embedding_model = AutoModel.from_pretrained(embedding_model_name).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0741775e-c325-4e58-baca-1d70279454be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertModel(\n",
       "  (embeddings): BertEmbeddings(\n",
       "    (word_embeddings): Embedding(30522, 384, padding_idx=0)\n",
       "    (position_embeddings): Embedding(512, 384)\n",
       "    (token_type_embeddings): Embedding(2, 384)\n",
       "    (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (encoder): BertEncoder(\n",
       "    (layer): ModuleList(\n",
       "      (0-5): 6 x BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSdpaSelfAttention(\n",
       "            (query): Linear(in_features=384, out_features=384, bias=True)\n",
       "            (key): Linear(in_features=384, out_features=384, bias=True)\n",
       "            (value): Linear(in_features=384, out_features=384, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=384, out_features=384, bias=True)\n",
       "            (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=384, out_features=1536, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=1536, out_features=384, bias=True)\n",
       "          (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pooler): BertPooler(\n",
       "    (dense): Linear(in_features=384, out_features=384, bias=True)\n",
       "    (activation): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cef31d0f-5e44-4199-8efa-31e6ac238dde",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_frames(video_path, frames_dir=\"./\", frame_rate=2):\n",
    "    \"\"\"Extract frames from a video at a specific rate and save to a directory.\"\"\"\n",
    "    video_name = Path(video_path).stem\n",
    "    video_frames_dir = Path(frames_dir) / video_name\n",
    "    video_frames_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    interval = int(fps / frame_rate)\n",
    "    frame_count = 0\n",
    "    saved_count = 0\n",
    "\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        if frame_count % interval == 0:\n",
    "            frame_path = video_frames_dir / f\"{saved_count:06d}.jpg\"\n",
    "            cv2.imwrite(str(frame_path), frame)\n",
    "            saved_count += 1\n",
    "        frame_count += 1\n",
    "\n",
    "    cap.release()\n",
    "    print(f\"Extracted {saved_count} frames from {video_path} to {video_frames_dir}\")\n",
    "    return video_frames_dir, saved_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c16048d6-b94c-4032-817c-2dc95e00ff7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "video_path = \"./op_1_0320241830.mp4\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8882bafe-1323-49d8-b23b-6511da3a6ba7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted 21 frames from ./op_1_0320241830.mp4 to op_1_0320241830\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(PosixPath('op_1_0320241830'), 21)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extract_frames(video_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1c33a44e-f7a5-4a02-8702-3ed2d1d1b974",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "\n",
    "def generate_captions(frames_dir):\n",
    "    \"\"\"Generate captions for each frame using Kosmos-2 model.\"\"\"\n",
    "    captions = []\n",
    "    # best_prompt = \"Describe the scene in the image with a focus on customer behavior and interactions at a self-checkout station in a shopping mall. Identify actions involving items, scanning devices, or the checkout process. Include any notable body language (e.g., excessive glancing, hiding items, or hesitating), interactions with the environment (e.g., shelves, bagging area, or scanning devices), and deviations from typical checkout behavior. Ensure the description highlights any suspicious or unusual activity.\"\n",
    "    prompt = \"Describe the scene in the image with a focus on customer behavior and what they are doing with their hands. Ensure the description highlights any possible action of theft or suspicious activity \\n Description:\"\n",
    "    \n",
    "\n",
    "    for frame_path in sorted(frames_dir.glob(\"*.jpg\")):\n",
    "        try:\n",
    "            # Load the image using PIL\n",
    "            image = Image.open(frame_path).convert(\"RGB\")\n",
    "\n",
    "            # Preprocess the image and prompt text\n",
    "            inputs = caption_processor(text=prompt, images=image, return_tensors=\"pt\").to(device)\n",
    "\n",
    "            # Generate caption with all required inputs\n",
    "            generated_ids = caption_model.generate(\n",
    "                pixel_values=inputs[\"pixel_values\"],\n",
    "                input_ids=inputs[\"input_ids\"],\n",
    "                attention_mask=inputs[\"attention_mask\"],\n",
    "                image_embeds=None,  # Not precomputed, so pass None\n",
    "                image_embeds_position_mask=inputs[\"image_embeds_position_mask\"],\n",
    "                use_cache=True,\n",
    "                max_new_tokens=128,\n",
    "            )\n",
    "\n",
    "            # Decode the generated caption\n",
    "            generated_text = caption_processor.batch_decode(generated_ids, skip_special_tokens=True)[0]\n",
    "\n",
    "            # Clean up and extract meaningful output\n",
    "            processed_text = caption_processor.post_process_generation(generated_text, cleanup_and_extract=True)[0]\n",
    "            \n",
    "            # Remove the initial prompt from the result\n",
    "            if \"Description:\" in generated_text:\n",
    "                processed_text = generated_text.split(\"Description:\")[1].strip()\n",
    "            else:\n",
    "                processed_text = generated_text.strip()\n",
    "\n",
    "            print(f\"{processed_text}\")\n",
    "\n",
    "            # Store the caption\n",
    "            captions.append((frame_path.stem, processed_text))\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {frame_path.name}: {e}\")\n",
    "            continue\n",
    "\n",
    "    return captions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "140e73be-8457-4da0-9814-78d47ba7185b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "frames_dir = \"./op_1_0320241830\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "599608ff-eb1b-4438-9209-07167046071a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The scene shows a man standing in a store aisle, looking at a display of plants and other items. He is holding a potted plant in his hand, possibly looking for a suitable plant to purchase. There are several other people in the store, some of whom are also looking at the plants. Some of them are standing closer to the man, while others are further away. The overall atmosphere suggests that the man is likely browsing the store for plants or other items to purchase, possibly for his home or garden.\n",
      "The scene shows a man standing in a grocery store aisle, looking at a display of plants. He is holding a potted plant in his hands, possibly looking for a suitable plant to purchase. The man is wearing a blue plaid shirt and appears to be focused on the plants. There are several other people in the store, some of whom are also looking at the plants and possibly browsing the aisles.\n",
      "The scene shows a man standing in a store aisle, looking at a display of potted plants. He is holding a potted plant in his hands, possibly examining it or deciding on a purchase. There are several potted plants on the shelf, with some closer to the man and others further away. The man appears to be focused on the plants, possibly considering their price, size, or color.\n",
      "The scene shows a man standing in a store aisle, looking at a display of potted plants. He is holding a potted plant in his hands, possibly examining it or deciding on a purchase. There are several potted plants on the shelf, with some closer to the man and others further away. The man appears to be focused on the plants, possibly looking for a specific plant or deciding if he wants to purchase it.\n",
      "In the image, a man is standing in a store aisle, looking at a display of plants. He is holding a potted plant in his hands, possibly examining it or deciding on a purchase. There are several other people in the scene, some of whom are also looking at the plants. Some of them are standing closer to the man, while others are further away. The overall atmosphere suggests that the man is likely engaged in a shopping experience or browsing the store's offerings.\n",
      "The scene shows a man standing in a grocery store aisle, looking at a display of plants. He is holding a potted plant in his hands, possibly looking for a suitable plant to purchase. There are several other people in the store, some of whom are also looking at the plants. Some of them are closer to the man, while others are further away. The overall atmosphere suggests that the man is likely shopping for plants, possibly for his home or garden.\n",
      "The scene shows a man standing in a store aisle, looking at a display of plants. He is holding a potted plant in his hands, possibly examining it or deciding on a purchase. There are several potted plants on the shelf, with some closer to the man and others further away. The man appears to be focused on the plants, possibly considering their price, size, or the quality of the plants.\n",
      "The scene shows a man standing in a store aisle, looking at a display of plants. He is wearing a blue plaid shirt and appears to be focused on the plants. There are several potted plants on the shelves, with some closer to the man and others further away. The man is also wearing glasses, which might indicate that he is looking at the plants from a distance.\n",
      "In the image, a man is standing in a store aisle, looking at a display of potted plants. He is holding a potted plant in his hands, possibly examining it or selecting it for purchase. There are several potted plants on the shelf, with some closer to the man and others further away. The man appears to be focused on the plants, possibly looking for a specific plant or deciding on a purchase.\n",
      "In the image, a man is standing in a store aisle, looking at a display of gardening supplies. He is holding a box of seeds, possibly looking for gardening tools or supplies. There are several other people in the store, some of whom are also looking at the display. Some of them are standing closer to the man, while others are further away. The scene suggests that the man is likely a customer or a shopper, and he is likely looking for the right gardening tools, seeds, or supplies to complete his gardening project.\n",
      "In the image, a man is standing in a store aisle, looking at a display of plants. He is wearing a blue plaid shirt and appears to be engaged in a conversation with someone. There are several other people in the scene, some of whom are also looking at the plants. Some of them are standing closer to the man, while others are further away. The overall atmosphere suggests that the man is likely a customer or a shopper in the store.\n",
      "In the image, a man is standing in a store aisle, looking at a display of items. He is wearing a blue shirt and appears to be engaged in a shopping activity. There are several other people in the scene, some of whom are also looking at the display. Some of them are standing closer to the man, while others are further away. The overall atmosphere suggests that the man is likely browsing the store's offerings and possibly making a purchase.\n",
      "In the image, a man is standing in a store aisle, looking at a display of gardening tools. He is holding a gardening tool in his hand, and he appears to be looking at the display. There are several other people in the store, some of whom are also looking at gardening tools, and some of them are standing closer to the man. The scene conveys a sense of curiosity and interest in the gardening tools displayed in the aisle.\n",
      "In the image, a man is standing in a store aisle, looking at a display of potted plants. He is holding a potted plant in his hand, possibly looking for a suitable plant to purchase. There are several potted plants on the shelf, with some closer to the man and others further away. The man appears to be focused on the plants, possibly considering which one to purchase or looking for inspiration.\n",
      "In the image, a man is standing in a store aisle, looking at a display of potted plants. He is holding a potted plant in his hand, possibly looking for a suitable plant to purchase. There are several potted plants on the shelf, with some closer to the man and others further away. The man appears to be focused on the plants, possibly considering which one to purchase or looking for inspiration.\n",
      "The scene shows a man standing in a grocery store aisle, looking at a display of potted plants. He is looking at the plants, possibly considering purchasing them. There are several potted plants on the shelves, with some closer to the man and others further away. The man is wearing a blue plaid shirt, which adds a casual and comfortable touch to his appearance.\n",
      "In the image, a man is standing in a store aisle, looking at a display of potted plants. He is looking at the plants, possibly considering purchasing them. He has his hands in his pockets, possibly indicating that he is looking for something to purchase. The scene captures the customer's attention and possibly indicates that he might be considering purchasing a potted plant.\n",
      "The scene shows a man standing in a grocery store aisle, looking at a display of various items. He appears to be looking at the items on the shelf, possibly considering purchasing them. There are several other people in the store, some of whom are also looking at or standing near the display. Some of them are closer to the left side of the image, while others are located towards the right side. The overall atmosphere suggests that the man is engaged in a shopping experience, possibly browsing the items or engaging in a conversation with others.\n",
      "The scene shows a man standing in a store aisle, looking at a display of gardening tools. He appears to be looking at the gardening tools, possibly considering purchasing them. There are several gardening tools on display, including a shovel, a rake, and a pair of scissors. The man is wearing a blue and white checkered shirt, which adds a casual and comfortable touch to his outfit.\n",
      "In the image, a man is standing in a store aisle, looking at a display of potted plants. He is holding a potted plant in his hand, possibly admiring it or considering purchasing it. Another person is also present in the scene, possibly a customer or a worker. The store is well-stocked with various potted plants, including several potted plants placed on shelves. There are several potted plant displays, with some of them being more prominent than others. The man is likely looking at the plants and deciding which one to purchase.\n",
      "In the image, a man is walking down the aisle of a store, looking at various items on display. He is holding a cell phone in his hand, possibly checking the time or browsing the store's offerings. The man's actions suggest that he might be engaged in a transaction or browsing for items.\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "captions = generate_captions(Path(frames_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8a11f11c-15f4-45a5-a8dd-5b01e27f5895",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('000000',\n",
       "  'The scene shows a man standing in a store aisle, looking at a display of plants and other items. He is holding a potted plant in his hand, possibly looking for a suitable plant to purchase. There are several other people in the store, some of whom are also looking at the plants. Some of them are standing closer to the man, while others are further away. The overall atmosphere suggests that the man is likely browsing the store for plants or other items to purchase, possibly for his home or garden.'),\n",
       " ('000001',\n",
       "  'The scene shows a man standing in a grocery store aisle, looking at a display of plants. He is holding a potted plant in his hands, possibly looking for a suitable plant to purchase. The man is wearing a blue plaid shirt and appears to be focused on the plants. There are several other people in the store, some of whom are also looking at the plants and possibly browsing the aisles.'),\n",
       " ('000002',\n",
       "  'The scene shows a man standing in a store aisle, looking at a display of potted plants. He is holding a potted plant in his hands, possibly examining it or deciding on a purchase. There are several potted plants on the shelf, with some closer to the man and others further away. The man appears to be focused on the plants, possibly considering their price, size, or color.'),\n",
       " ('000003',\n",
       "  'The scene shows a man standing in a store aisle, looking at a display of potted plants. He is holding a potted plant in his hands, possibly examining it or deciding on a purchase. There are several potted plants on the shelf, with some closer to the man and others further away. The man appears to be focused on the plants, possibly looking for a specific plant or deciding if he wants to purchase it.'),\n",
       " ('000004',\n",
       "  \"In the image, a man is standing in a store aisle, looking at a display of plants. He is holding a potted plant in his hands, possibly examining it or deciding on a purchase. There are several other people in the scene, some of whom are also looking at the plants. Some of them are standing closer to the man, while others are further away. The overall atmosphere suggests that the man is likely engaged in a shopping experience or browsing the store's offerings.\"),\n",
       " ('000005',\n",
       "  'The scene shows a man standing in a grocery store aisle, looking at a display of plants. He is holding a potted plant in his hands, possibly looking for a suitable plant to purchase. There are several other people in the store, some of whom are also looking at the plants. Some of them are closer to the man, while others are further away. The overall atmosphere suggests that the man is likely shopping for plants, possibly for his home or garden.'),\n",
       " ('000006',\n",
       "  'The scene shows a man standing in a store aisle, looking at a display of plants. He is holding a potted plant in his hands, possibly examining it or deciding on a purchase. There are several potted plants on the shelf, with some closer to the man and others further away. The man appears to be focused on the plants, possibly considering their price, size, or the quality of the plants.'),\n",
       " ('000007',\n",
       "  'The scene shows a man standing in a store aisle, looking at a display of plants. He is wearing a blue plaid shirt and appears to be focused on the plants. There are several potted plants on the shelves, with some closer to the man and others further away. The man is also wearing glasses, which might indicate that he is looking at the plants from a distance.'),\n",
       " ('000008',\n",
       "  'In the image, a man is standing in a store aisle, looking at a display of potted plants. He is holding a potted plant in his hands, possibly examining it or selecting it for purchase. There are several potted plants on the shelf, with some closer to the man and others further away. The man appears to be focused on the plants, possibly looking for a specific plant or deciding on a purchase.'),\n",
       " ('000009',\n",
       "  'In the image, a man is standing in a store aisle, looking at a display of gardening supplies. He is holding a box of seeds, possibly looking for gardening tools or supplies. There are several other people in the store, some of whom are also looking at the display. Some of them are standing closer to the man, while others are further away. The scene suggests that the man is likely a customer or a shopper, and he is likely looking for the right gardening tools, seeds, or supplies to complete his gardening project.'),\n",
       " ('000010',\n",
       "  'In the image, a man is standing in a store aisle, looking at a display of plants. He is wearing a blue plaid shirt and appears to be engaged in a conversation with someone. There are several other people in the scene, some of whom are also looking at the plants. Some of them are standing closer to the man, while others are further away. The overall atmosphere suggests that the man is likely a customer or a shopper in the store.'),\n",
       " ('000011',\n",
       "  \"In the image, a man is standing in a store aisle, looking at a display of items. He is wearing a blue shirt and appears to be engaged in a shopping activity. There are several other people in the scene, some of whom are also looking at the display. Some of them are standing closer to the man, while others are further away. The overall atmosphere suggests that the man is likely browsing the store's offerings and possibly making a purchase.\"),\n",
       " ('000012',\n",
       "  'In the image, a man is standing in a store aisle, looking at a display of gardening tools. He is holding a gardening tool in his hand, and he appears to be looking at the display. There are several other people in the store, some of whom are also looking at gardening tools, and some of them are standing closer to the man. The scene conveys a sense of curiosity and interest in the gardening tools displayed in the aisle.'),\n",
       " ('000013',\n",
       "  'In the image, a man is standing in a store aisle, looking at a display of potted plants. He is holding a potted plant in his hand, possibly looking for a suitable plant to purchase. There are several potted plants on the shelf, with some closer to the man and others further away. The man appears to be focused on the plants, possibly considering which one to purchase or looking for inspiration.'),\n",
       " ('000014',\n",
       "  'In the image, a man is standing in a store aisle, looking at a display of potted plants. He is holding a potted plant in his hand, possibly looking for a suitable plant to purchase. There are several potted plants on the shelf, with some closer to the man and others further away. The man appears to be focused on the plants, possibly considering which one to purchase or looking for inspiration.'),\n",
       " ('000015',\n",
       "  'The scene shows a man standing in a grocery store aisle, looking at a display of potted plants. He is looking at the plants, possibly considering purchasing them. There are several potted plants on the shelves, with some closer to the man and others further away. The man is wearing a blue plaid shirt, which adds a casual and comfortable touch to his appearance.'),\n",
       " ('000016',\n",
       "  \"In the image, a man is standing in a store aisle, looking at a display of potted plants. He is looking at the plants, possibly considering purchasing them. He has his hands in his pockets, possibly indicating that he is looking for something to purchase. The scene captures the customer's attention and possibly indicates that he might be considering purchasing a potted plant.\"),\n",
       " ('000017',\n",
       "  'The scene shows a man standing in a grocery store aisle, looking at a display of various items. He appears to be looking at the items on the shelf, possibly considering purchasing them. There are several other people in the store, some of whom are also looking at or standing near the display. Some of them are closer to the left side of the image, while others are located towards the right side. The overall atmosphere suggests that the man is engaged in a shopping experience, possibly browsing the items or engaging in a conversation with others.'),\n",
       " ('000018',\n",
       "  'The scene shows a man standing in a store aisle, looking at a display of gardening tools. He appears to be looking at the gardening tools, possibly considering purchasing them. There are several gardening tools on display, including a shovel, a rake, and a pair of scissors. The man is wearing a blue and white checkered shirt, which adds a casual and comfortable touch to his outfit.'),\n",
       " ('000019',\n",
       "  'In the image, a man is standing in a store aisle, looking at a display of potted plants. He is holding a potted plant in his hand, possibly admiring it or considering purchasing it. Another person is also present in the scene, possibly a customer or a worker. The store is well-stocked with various potted plants, including several potted plants placed on shelves. There are several potted plant displays, with some of them being more prominent than others. The man is likely looking at the plants and deciding which one to purchase.'),\n",
       " ('000020',\n",
       "  \"In the image, a man is walking down the aisle of a store, looking at various items on display. He is holding a cell phone in his hand, possibly checking the time or browsing the store's offerings. The man's actions suggest that he might be engaged in a transaction or browsing for items.\")]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "captions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2f85531d-b378-4663-9d10-f6abd71ffc7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_texts(texts, tokenizer, model):\n",
    "    \"\"\"\n",
    "    Encode a list of texts into embeddings using a Hugging Face model.\n",
    "\n",
    "    Args:\n",
    "        texts (list of str): List of input texts to encode.\n",
    "        tokenizer: Hugging Face tokenizer.\n",
    "        model: Hugging Face model.\n",
    "\n",
    "    Returns:\n",
    "        numpy.ndarray: Embeddings for the input texts.\n",
    "    \"\"\"\n",
    "    inputs = tokenizer(texts, padding=True, truncation=True, return_tensors=\"pt\")\n",
    "    inputs = {key: value.to(model.device) for key, value in inputs.items()}\n",
    "\n",
    "    # Get embeddings from the model\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        embeddings = outputs.last_hidden_state.mean(dim=1).cpu().numpy()  # Use mean pooling\n",
    "    return embeddings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "755b5273-f317-4a91-af20-521a5a799581",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_faiss_index(captions):\n",
    "    \"\"\"\n",
    "    Create a FAISS index to store and search embeddings for caption similarity.\n",
    "\n",
    "    Args:\n",
    "        captions (list of tuples): Each tuple contains (frame_id, caption_text), where 'caption_text' is a caption\n",
    "                                   string to be embedded and indexed.\n",
    "\n",
    "    Returns:\n",
    "        index (faiss.IndexFlatL2): A FAISS index with stored embeddings that allows similarity searches.\n",
    "        captions (list of tuples): The original captions list, which maintains the frame and caption structure.\n",
    "    \"\"\"\n",
    "    # Extract the caption text from each tuple (frame_id, caption_text) for embedding\n",
    "    captions_text = [caption[1] for caption in captions]\n",
    "\n",
    "    # Generate embeddings for each caption using the Hugging Face embedding model\n",
    "    embeddings = encode_texts(captions_text, embedding_tokenizer, embedding_model)\n",
    "\n",
    "    # Initialize a FAISS index with L2 (Euclidean) distance metric using the dimensionality of the embeddings\n",
    "    index = faiss.IndexFlatL2(embeddings.shape[1])\n",
    "\n",
    "    # Add the embeddings to the FAISS index, enabling fast similarity search on these vectors\n",
    "    index.add(embeddings)\n",
    "\n",
    "    # Return both the FAISS index and the original captions list for later retrieval and reference\n",
    "    return index, captions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cdaa5b40-413b-4e21-b34a-e295690c2e51",
   "metadata": {},
   "outputs": [],
   "source": [
    "index, captions = create_faiss_index(captions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "06985078-8cfd-422a-83d2-898a16c53ae9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<faiss.swigfaiss.IndexFlatL2; proxy of <Swig Object of type 'faiss::IndexFlatL2 *' at 0x719eb074b060> >"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "314363eb-a6c8-4dab-827f-e94026aad46a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def refine_captions(index, captions, k=5):\n",
    "    \"\"\"\n",
    "    Refine captions by finding the most semantically similar captions within a neighborhood using FAISS.\n",
    "\n",
    "    Args:\n",
    "        index (faiss.IndexFlatL2): A FAISS index containing embeddings for similarity search.\n",
    "        captions (list of tuples): Original captions with structure (frame_id, caption_text).\n",
    "        k (int): Number of nearest neighbors to consider.\n",
    "\n",
    "    Returns:\n",
    "        list of tuples: Refined captions with the same structure as the input.\n",
    "    \"\"\"\n",
    "    # Extract the caption text from each tuple for embedding\n",
    "    captions_text = [caption[1] for caption in captions]\n",
    "\n",
    "    # Generate embeddings for the captions using the Hugging Face embedding model\n",
    "    embeddings = encode_texts(captions_text, embedding_tokenizer, embedding_model)\n",
    "\n",
    "    # Search for the k nearest neighbors in the FAISS index\n",
    "    _, neighbors = index.search(embeddings, k)\n",
    "\n",
    "    # Refine captions based on the most frequent neighbor caption\n",
    "    refined_captions = []\n",
    "    for idx, neighbor_indices in enumerate(neighbors):\n",
    "        neighbor_texts = [captions[neighbor][1] for neighbor in neighbor_indices]\n",
    "        most_frequent_caption = max(set(neighbor_texts), key=neighbor_texts.count)\n",
    "        refined_captions.append((captions[idx][0], most_frequent_caption))\n",
    "    \n",
    "    return refined_captions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "94ec225a-5e3b-45d2-8f4e-51b6ba412385",
   "metadata": {},
   "outputs": [],
   "source": [
    "refined_captions = refine_captions(index, captions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ee793edb-dcbb-4487-959d-7e08f21dede1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('000000',\n",
       "  'The scene shows a man standing in a grocery store aisle, looking at a display of plants. He is holding a potted plant in his hands, possibly looking for a suitable plant to purchase. There are several other people in the store, some of whom are also looking at the plants. Some of them are closer to the man, while others are further away. The overall atmosphere suggests that the man is likely shopping for plants, possibly for his home or garden.'),\n",
       " ('000001',\n",
       "  'The scene shows a man standing in a grocery store aisle, looking at a display of plants. He is holding a potted plant in his hands, possibly looking for a suitable plant to purchase. There are several other people in the store, some of whom are also looking at the plants. Some of them are closer to the man, while others are further away. The overall atmosphere suggests that the man is likely shopping for plants, possibly for his home or garden.'),\n",
       " ('000002',\n",
       "  'In the image, a man is standing in a store aisle, looking at a display of potted plants. He is holding a potted plant in his hand, possibly looking for a suitable plant to purchase. There are several potted plants on the shelf, with some closer to the man and others further away. The man appears to be focused on the plants, possibly considering which one to purchase or looking for inspiration.'),\n",
       " ('000003',\n",
       "  'In the image, a man is standing in a store aisle, looking at a display of potted plants. He is holding a potted plant in his hand, possibly looking for a suitable plant to purchase. There are several potted plants on the shelf, with some closer to the man and others further away. The man appears to be focused on the plants, possibly considering which one to purchase or looking for inspiration.'),\n",
       " ('000004',\n",
       "  'The scene shows a man standing in a grocery store aisle, looking at a display of plants. He is holding a potted plant in his hands, possibly looking for a suitable plant to purchase. There are several other people in the store, some of whom are also looking at the plants. Some of them are closer to the man, while others are further away. The overall atmosphere suggests that the man is likely shopping for plants, possibly for his home or garden.'),\n",
       " ('000005',\n",
       "  'The scene shows a man standing in a grocery store aisle, looking at a display of plants. He is holding a potted plant in his hands, possibly looking for a suitable plant to purchase. There are several other people in the store, some of whom are also looking at the plants. Some of them are closer to the man, while others are further away. The overall atmosphere suggests that the man is likely shopping for plants, possibly for his home or garden.'),\n",
       " ('000006',\n",
       "  'In the image, a man is standing in a store aisle, looking at a display of potted plants. He is holding a potted plant in his hand, possibly looking for a suitable plant to purchase. There are several potted plants on the shelf, with some closer to the man and others further away. The man appears to be focused on the plants, possibly considering which one to purchase or looking for inspiration.'),\n",
       " ('000007',\n",
       "  'The scene shows a man standing in a store aisle, looking at a display of plants. He is wearing a blue plaid shirt and appears to be focused on the plants. There are several potted plants on the shelves, with some closer to the man and others further away. The man is also wearing glasses, which might indicate that he is looking at the plants from a distance.'),\n",
       " ('000008',\n",
       "  'In the image, a man is standing in a store aisle, looking at a display of potted plants. He is holding a potted plant in his hand, possibly looking for a suitable plant to purchase. There are several potted plants on the shelf, with some closer to the man and others further away. The man appears to be focused on the plants, possibly considering which one to purchase or looking for inspiration.'),\n",
       " ('000009',\n",
       "  'In the image, a man is standing in a store aisle, looking at a display of gardening supplies. He is holding a box of seeds, possibly looking for gardening tools or supplies. There are several other people in the store, some of whom are also looking at the display. Some of them are standing closer to the man, while others are further away. The scene suggests that the man is likely a customer or a shopper, and he is likely looking for the right gardening tools, seeds, or supplies to complete his gardening project.'),\n",
       " ('000010',\n",
       "  \"In the image, a man is standing in a store aisle, looking at a display of items. He is wearing a blue shirt and appears to be engaged in a shopping activity. There are several other people in the scene, some of whom are also looking at the display. Some of them are standing closer to the man, while others are further away. The overall atmosphere suggests that the man is likely browsing the store's offerings and possibly making a purchase.\"),\n",
       " ('000011',\n",
       "  \"In the image, a man is standing in a store aisle, looking at a display of items. He is wearing a blue shirt and appears to be engaged in a shopping activity. There are several other people in the scene, some of whom are also looking at the display. Some of them are standing closer to the man, while others are further away. The overall atmosphere suggests that the man is likely browsing the store's offerings and possibly making a purchase.\"),\n",
       " ('000012',\n",
       "  'The scene shows a man standing in a grocery store aisle, looking at a display of plants. He is holding a potted plant in his hands, possibly looking for a suitable plant to purchase. There are several other people in the store, some of whom are also looking at the plants. Some of them are closer to the man, while others are further away. The overall atmosphere suggests that the man is likely shopping for plants, possibly for his home or garden.'),\n",
       " ('000013',\n",
       "  'In the image, a man is standing in a store aisle, looking at a display of potted plants. He is holding a potted plant in his hand, possibly looking for a suitable plant to purchase. There are several potted plants on the shelf, with some closer to the man and others further away. The man appears to be focused on the plants, possibly considering which one to purchase or looking for inspiration.'),\n",
       " ('000014',\n",
       "  'In the image, a man is standing in a store aisle, looking at a display of potted plants. He is holding a potted plant in his hand, possibly looking for a suitable plant to purchase. There are several potted plants on the shelf, with some closer to the man and others further away. The man appears to be focused on the plants, possibly considering which one to purchase or looking for inspiration.'),\n",
       " ('000015',\n",
       "  'The scene shows a man standing in a store aisle, looking at a display of plants. He is wearing a blue plaid shirt and appears to be focused on the plants. There are several potted plants on the shelves, with some closer to the man and others further away. The man is also wearing glasses, which might indicate that he is looking at the plants from a distance.'),\n",
       " ('000016',\n",
       "  'In the image, a man is standing in a store aisle, looking at a display of potted plants. He is holding a potted plant in his hand, possibly looking for a suitable plant to purchase. There are several potted plants on the shelf, with some closer to the man and others further away. The man appears to be focused on the plants, possibly considering which one to purchase or looking for inspiration.'),\n",
       " ('000017',\n",
       "  \"In the image, a man is standing in a store aisle, looking at a display of items. He is wearing a blue shirt and appears to be engaged in a shopping activity. There are several other people in the scene, some of whom are also looking at the display. Some of them are standing closer to the man, while others are further away. The overall atmosphere suggests that the man is likely browsing the store's offerings and possibly making a purchase.\"),\n",
       " ('000018',\n",
       "  'The scene shows a man standing in a store aisle, looking at a display of gardening tools. He appears to be looking at the gardening tools, possibly considering purchasing them. There are several gardening tools on display, including a shovel, a rake, and a pair of scissors. The man is wearing a blue and white checkered shirt, which adds a casual and comfortable touch to his outfit.'),\n",
       " ('000019',\n",
       "  'The scene shows a man standing in a grocery store aisle, looking at a display of plants. He is holding a potted plant in his hands, possibly looking for a suitable plant to purchase. There are several other people in the store, some of whom are also looking at the plants. Some of them are closer to the man, while others are further away. The overall atmosphere suggests that the man is likely shopping for plants, possibly for his home or garden.'),\n",
       " ('000020',\n",
       "  'In the image, a man is standing in a store aisle, looking at a display of potted plants. He is holding a potted plant in his hands, possibly examining it or selecting it for purchase. There are several potted plants on the shelf, with some closer to the man and others further away. The man appears to be focused on the plants, possibly looking for a specific plant or deciding on a purchase.')]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "refined_captions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5f1a879e-c71e-416a-809e-49398eb5a09f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Note: Environment variable`HF_TOKEN` is set and is the current active token independently from the token you've just configured.\n"
     ]
    }
   ],
   "source": [
    "#Login HuggingFace\n",
    "import os\n",
    "os.environ[\"HF_TOKEN\"] = \"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\"\n",
    "\n",
    "from huggingface_hub import login\n",
    "login(token=os.environ[\"HF_TOKEN\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ab768934-7660-4aee-8722-aa2f0ddc0fef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6775056384\n",
      "7732199424\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.cuda.memory_allocated())\n",
    "print(torch.cuda.memory_reserved())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ea8afb4a-5953-4c8b-abc0-f5603ae8a6ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Release GPU memory\n",
    "del caption_model  # Delete the Komos model\n",
    "del caption_processor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a024b0f8-6951-4fe9-a8da-00650869ca5b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "595e60aa-fcec-4356-a752-458f6516b117",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "# import torch\n",
    "\n",
    "# summarizer_name = \"google/flan-t5-large\"\n",
    "\n",
    "# summarizer_tokenizer = AutoTokenizer.from_pretrained(summarizer_name)\n",
    "# summarizer_model = AutoModelForSeq2SeqLM.from_pretrained(summarizer_name).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "13e1916b-b849-4ef9-a618-10d91ab2f652",
   "metadata": {},
   "outputs": [],
   "source": [
    "# summarizer_tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "1f98c1bc-ab37-4991-961d-963c9e2e67c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def temporal_summaries(refined_captions, window_size=5):\n",
    "#     \"\"\"\n",
    "#     Generate concise temporal summaries for each frame based on surrounding captions using FLAN-T5.\n",
    "#     \"\"\"\n",
    "#     summaries = []\n",
    "#     half_window = window_size // 2\n",
    "\n",
    "#     for i in range(len(refined_captions)):\n",
    "#         # Define the range around the current caption to form the temporal context\n",
    "#         start = max(0, i - half_window)\n",
    "#         end = min(len(refined_captions), i + half_window + 1)\n",
    "\n",
    "#         # Collect unique captions in the defined window\n",
    "#         temporal_description = list(set(refined_captions[j][1] for j in range(start, end)))\n",
    "\n",
    "#         # Combine captions into a single description\n",
    "#         temporal_description_text = \"\\n\".join([f\"Scene {i+1} {temporal_description[1]}\" for i in range(len(temporal_description))])\n",
    "\n",
    "#         # Create the prompt specifically for FLAN-T5 summarization\n",
    "#         prompt = (\n",
    "#             \"Summarize the following scene descriptions into one scene.\"\n",
    "#             f\"{temporal_description_text}\"\n",
    "#         )\n",
    "\n",
    "#         print(prompt, \"\\n\\n\\n\")\n",
    "\n",
    "#         # Encode the prompt for FLAN-T5\n",
    "#         inputs = summarizer_tokenizer(prompt, return_tensors=\"pt\").to(device)\n",
    "#         output = summarizer_model.generate(**inputs, max_new_tokens=100)\n",
    "#         summary = summarizer_tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "\n",
    "#         # Append the summary to the list of summaries\n",
    "#         summaries.append(summary)\n",
    "\n",
    "#     return summaries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "359ae959-26c1-4a8f-a9c0-807c059b339a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'In the image, a man is standing in a store aisle, looking at a display of potted plants. He is holding a potted plant in his hand, possibly looking for a suitable plant to purchase. There are several potted plants on the shelf, with some closer to the man and others further away. The man appears to be focused on the plants, possibly considering which one to purchase or looking for inspiration.'"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = \"\\n\".join([text[1] for text in refined_captions[:5]])\n",
    "inputs = summarizer_tokenizer(prompt, return_tensors=\"pt\").to(device)\n",
    "output = summarizer_model.generate(**inputs, max_new_tokens=100)\n",
    "summary = summarizer_tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "54d27795-ceac-4f6f-93c5-b6a1ecc192e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading shards: 100%|██████████| 2/2 [01:03<00:00, 31.55s/it]\n",
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.37s/it]\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import torch\n",
    "\n",
    "# Set up the LLaMA-2 model (or any desired LLM) and tokenizer on the correct device\n",
    "llm_model_name = \"meta-llama/Llama-2-7b-chat-hf\"\n",
    "\n",
    "llm_tokenizer = AutoTokenizer.from_pretrained(llm_model_name)\n",
    "llm_model = AutoModelForCausalLM.from_pretrained(llm_model_name).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78ec3c01-7540-4510-8f29-d55d52aa59d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "8fc6ebfa-cab1-45cc-b8c9-f1befc25a56c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def temporal_summaries(refined_captions, window_size=5):\n",
    "    \"\"\"\n",
    "    Generate concise temporal summaries for each frame based on surrounding captions using FLAN-T5.\n",
    "    \"\"\"\n",
    "    summaries = []\n",
    "    half_window = window_size // 2\n",
    "\n",
    "    for i in range(len(refined_captions)):\n",
    "        # Define the range around the current caption to form the temporal context\n",
    "        start = max(0, i - half_window)\n",
    "        end = min(len(refined_captions), i + half_window + 1)\n",
    "\n",
    "        # Collect unique captions in the defined window\n",
    "        temporal_description = list(set(refined_captions[j][1] for j in range(start, end)))\n",
    "\n",
    "        # Combine captions into a single description\n",
    "        temporal_description_text = \"\\n\".join([f\"Scene {i+1} {temporal_description[1]}\" for i in range(len(temporal_description))])\n",
    "\n",
    "        # Create the prompt specifically for LLama summarization\n",
    "        prompt = (\n",
    "            \"Summarize the following scene descriptions into one scene.\"\n",
    "            f\"{temporal_description_text}\"\n",
    "            \"The Summary:\"\n",
    "        )\n",
    "\n",
    "        # print(prompt, \"\\n\\n\\n\")\n",
    "\n",
    "        # Encode the prompt for Llama\n",
    "        inputs = llm_tokenizer(prompt, return_tensors=\"pt\").to(device)\n",
    "        output = llm_model.generate(**inputs, max_new_tokens=100)\n",
    "        summary = llm_tokenizer.decode(output[0])\n",
    "\n",
    "        # Remove the initial prompt from the result\n",
    "        if \"The Summary:\" in summary:\n",
    "            summary = summary.split(\"The Summary:\")[1].strip()\n",
    "        else:\n",
    "            summary = summary.strip()\n",
    "\n",
    "        print(\"result\", summary)\n",
    "\n",
    "        # Append the summary to the list of summaries\n",
    "        summaries.append(summary)\n",
    "\n",
    "    return summaries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "3ca469f7-7f78-4aa6-9871-d9225cc5d0fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result The scene shows a man shopping for plants in a grocery store aisle, holding a potted plant in his hands and surrounded by other people who are also looking at the plants. The atmosphere suggests that the man is likely shopping for plants for his home or garden.</s>\n",
      "result A man is standing in a grocery store aisle, holding a potted plant and looking at a display of plants. There are other people in the store, some closer and others further away, all with varying levels of interest in the plants. The atmosphere suggests the man is shopping for plants for his home or garden.</s>\n",
      "result A man is standing in a grocery store aisle, looking at a display of plants. He is holding a potted plant in his hands and appears to be shopping for a suitable plant to purchase. There are several other people in the store, some of whom are closer to the man, while others are further away. The overall atmosphere suggests that the man is shopping for plants, possibly for his home or garden.</s>\n",
      "result The scene shows a man shopping in a grocery store, specifically looking at a display of plants. He is holding a potted plant in his hands and there are other people in the store who are also looking at the plants. The overall atmosphere suggests that the man is shopping for plants, possibly for his home or garden.</s>\n",
      "result The scene shows a man shopping in a grocery store, specifically looking at a display of plants. He is holding a potted plant in his hands, possibly considering purchasing it. There are other people in the store, some of whom are also looking at the plants. The atmosphere is one of people shopping for plants, possibly for their home or garden.</s>\n",
      "result The scene shows a man shopping in a grocery store for plants. He is holding a potted plant in his hands and looking at a display of plants. There are other people in the store who are also looking at the plants, some closer to the man and others further away. The atmosphere suggests that the man is likely shopping for plants for his home or garden.</s>\n",
      "result The scene shows a man shopping for plants in a grocery store aisle, looking at a display of plants and possibly considering purchasing one. There are other people in the store who are also looking at the plants, some of whom are closer to the man while others are further away. The atmosphere suggests that the man is likely shopping for plants for his home or garden.</s>\n",
      "result The scene shows a man shopping for plants in a grocery store aisle, looking at a display of plants and possibly holding a potted plant in his hands. There are other people in the store, some closer and some further away from the man. The atmosphere suggests that the man is likely shopping for plants for his home or garden.</s>\n",
      "result The scene descriptions are identical and describe a man standing in a store aisle, looking at a display of items, wearing a blue shirt, and engaging in a shopping activity. The atmosphere suggests that the man is browsing the store's offerings and possibly making a purchase.</s>\n",
      "result In all four scenes, a man is standing in a store aisle, looking at a display of items. He is wearing a blue shirt and appears to be engaged in a shopping activity. There are several other people in the scene, some of whom are also looking at the display. The overall atmosphere suggests that the man is likely browsing the store's offerings and possibly making a purchase.</s>\n",
      "result The scene depicts a man browsing a store's offerings, possibly making a purchase, in a busy aisle with other people nearby. The man is wearing a blue shirt and appears to be engaged in the shopping activity.</s>\n",
      "result The scene describes a man standing in a store aisle, looking at a display of items while wearing a blue shirt. There are other people in the scene, some closer and some further away, with an overall atmosphere suggesting the man is browsing and possibly making a purchase.</s>\n",
      "result In each of the three scenes, a man is standing in a store aisle, looking at a display of items. He is wearing a blue shirt and appears to be engaged in a shopping activity. There are several other people in the scene, some of whom are also looking at the display. The overall atmosphere suggests that the man is likely browsing the store's offerings and possibly making a purchase.</s>\n",
      "result In all four scenes, a man is standing in a store aisle, looking at a display of items. He is wearing a blue shirt and appears to be engaged in a shopping activity. There are several other people in the scene, some of whom are also looking at the display. The overall atmosphere suggests that the man is likely browsing the store's offerings and possibly making a purchase.</s>\n",
      "result The scene shows a man shopping for plants in a grocery store aisle, holding a potted plant in his hands and surrounded by other people who are also looking at the plants. The overall atmosphere suggests that the man is likely shopping for plants for his home or garden.</s>\n",
      "result The scene depicts a man standing in a store aisle, surrounded by other people who are also browsing the offerings. The man is wearing a blue shirt and appears to be engaged in a shopping activity. The overall atmosphere is one of browsing and possible purchasing.</s>\n",
      "result The scene depicts a man standing in a store aisle, browsing a display of items while wearing a blue shirt. There are several other people in the scene, some of whom are also looking at the display. The atmosphere suggests that the man may be making a purchase.</s>\n",
      "result The scene is set in a grocery store where a man is shopping for plants. He is standing in an aisle, looking at a display of plants, and holding a potted plant in his hands. There are several other people in the store, some of whom are also looking at the plants. The overall atmosphere is one of shopping for plants, possibly for home or garden use.</s>\n",
      "result The scene shows a man standing in a grocery store aisle, looking at a display of plants. He is holding a potted plant in his hands, possibly looking for a suitable plant to purchase. There are several other people in the store, some of whom are also looking at the plants. The overall atmosphere suggests that the man is likely shopping for plants, possibly for his home or garden.</s>\n",
      "result The scene depicts a man standing in a store aisle, surrounded by other people who are also browsing the display of items. The man is wearing a blue shirt and appears to be engaged in a shopping activity. The overall atmosphere is one of casual browsing and possible purchases.</s>\n",
      "result The scene shows a man standing in a store aisle, looking at a display of gardening tools. He appears to be considering purchasing them, and is wearing a casual blue and white checkered shirt.</s>\n"
     ]
    }
   ],
   "source": [
    "summaries = temporal_summaries(refined_captions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "5a541b0d-c1ed-4b46-aceb-10edebc1a614",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The scene shows a man shopping for plants in a grocery store aisle, holding a potted plant in his hands and surrounded by other people who are also looking at the plants. The atmosphere suggests that the man is likely shopping for plants for his home or garden.</s>',\n",
       " 'A man is standing in a grocery store aisle, holding a potted plant and looking at a display of plants. There are other people in the store, some closer and others further away, all with varying levels of interest in the plants. The atmosphere suggests the man is shopping for plants for his home or garden.</s>',\n",
       " 'A man is standing in a grocery store aisle, looking at a display of plants. He is holding a potted plant in his hands and appears to be shopping for a suitable plant to purchase. There are several other people in the store, some of whom are closer to the man, while others are further away. The overall atmosphere suggests that the man is shopping for plants, possibly for his home or garden.</s>',\n",
       " 'The scene shows a man shopping in a grocery store, specifically looking at a display of plants. He is holding a potted plant in his hands and there are other people in the store who are also looking at the plants. The overall atmosphere suggests that the man is shopping for plants, possibly for his home or garden.</s>',\n",
       " 'The scene shows a man shopping in a grocery store, specifically looking at a display of plants. He is holding a potted plant in his hands, possibly considering purchasing it. There are other people in the store, some of whom are also looking at the plants. The atmosphere is one of people shopping for plants, possibly for their home or garden.</s>',\n",
       " 'The scene shows a man shopping in a grocery store for plants. He is holding a potted plant in his hands and looking at a display of plants. There are other people in the store who are also looking at the plants, some closer to the man and others further away. The atmosphere suggests that the man is likely shopping for plants for his home or garden.</s>',\n",
       " 'The scene shows a man shopping for plants in a grocery store aisle, looking at a display of plants and possibly considering purchasing one. There are other people in the store who are also looking at the plants, some of whom are closer to the man while others are further away. The atmosphere suggests that the man is likely shopping for plants for his home or garden.</s>',\n",
       " 'The scene shows a man shopping for plants in a grocery store aisle, looking at a display of plants and possibly holding a potted plant in his hands. There are other people in the store, some closer and some further away from the man. The atmosphere suggests that the man is likely shopping for plants for his home or garden.</s>',\n",
       " \"The scene descriptions are identical and describe a man standing in a store aisle, looking at a display of items, wearing a blue shirt, and engaging in a shopping activity. The atmosphere suggests that the man is browsing the store's offerings and possibly making a purchase.</s>\",\n",
       " \"In all four scenes, a man is standing in a store aisle, looking at a display of items. He is wearing a blue shirt and appears to be engaged in a shopping activity. There are several other people in the scene, some of whom are also looking at the display. The overall atmosphere suggests that the man is likely browsing the store's offerings and possibly making a purchase.</s>\",\n",
       " \"The scene depicts a man browsing a store's offerings, possibly making a purchase, in a busy aisle with other people nearby. The man is wearing a blue shirt and appears to be engaged in the shopping activity.</s>\",\n",
       " 'The scene describes a man standing in a store aisle, looking at a display of items while wearing a blue shirt. There are other people in the scene, some closer and some further away, with an overall atmosphere suggesting the man is browsing and possibly making a purchase.</s>',\n",
       " \"In each of the three scenes, a man is standing in a store aisle, looking at a display of items. He is wearing a blue shirt and appears to be engaged in a shopping activity. There are several other people in the scene, some of whom are also looking at the display. The overall atmosphere suggests that the man is likely browsing the store's offerings and possibly making a purchase.</s>\",\n",
       " \"In all four scenes, a man is standing in a store aisle, looking at a display of items. He is wearing a blue shirt and appears to be engaged in a shopping activity. There are several other people in the scene, some of whom are also looking at the display. The overall atmosphere suggests that the man is likely browsing the store's offerings and possibly making a purchase.</s>\",\n",
       " 'The scene shows a man shopping for plants in a grocery store aisle, holding a potted plant in his hands and surrounded by other people who are also looking at the plants. The overall atmosphere suggests that the man is likely shopping for plants for his home or garden.</s>',\n",
       " 'The scene depicts a man standing in a store aisle, surrounded by other people who are also browsing the offerings. The man is wearing a blue shirt and appears to be engaged in a shopping activity. The overall atmosphere is one of browsing and possible purchasing.</s>',\n",
       " 'The scene depicts a man standing in a store aisle, browsing a display of items while wearing a blue shirt. There are several other people in the scene, some of whom are also looking at the display. The atmosphere suggests that the man may be making a purchase.</s>',\n",
       " 'The scene is set in a grocery store where a man is shopping for plants. He is standing in an aisle, looking at a display of plants, and holding a potted plant in his hands. There are several other people in the store, some of whom are also looking at the plants. The overall atmosphere is one of shopping for plants, possibly for home or garden use.</s>',\n",
       " 'The scene shows a man standing in a grocery store aisle, looking at a display of plants. He is holding a potted plant in his hands, possibly looking for a suitable plant to purchase. There are several other people in the store, some of whom are also looking at the plants. The overall atmosphere suggests that the man is likely shopping for plants, possibly for his home or garden.</s>',\n",
       " 'The scene depicts a man standing in a store aisle, surrounded by other people who are also browsing the display of items. The man is wearing a blue shirt and appears to be engaged in a shopping activity. The overall atmosphere is one of casual browsing and possible purchases.</s>',\n",
       " 'The scene shows a man standing in a store aisle, looking at a display of gardening tools. He appears to be considering purchasing them, and is wearing a casual blue and white checkered shirt.</s>']"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "480777fe-40ec-4b19-98d1-8d8e91e40f18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(summaries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "9bf4ff30-9a01-472d-b3cc-addf5d4bcb5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Release GPU memory\n",
    "# del summarizer_model  # Delete the summarizer model\n",
    "# del summarizer_tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "0d70b20b-7b00-43d9-81d4-6946e3a54070",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Nov 18 12:33:09 2024       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 550.90.12              Driver Version: 550.90.12      CUDA Version: 12.4     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA A100-SXM4-40GB          On  |   00000000:07:00.0 Off |                    0 |\n",
      "| N/A   42C    P0             73W /  400W |   30513MiB /  40960MiB |     94%      Default |\n",
      "|                                         |                        |             Disabled |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|    0   N/A  N/A      3999      C   /usr/bin/python3                            30504MiB |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a27901e6-768b-456e-a5ee-c65d3dcb7171",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "ac291623-30c4-4227-af3f-48bb59274ca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def anomaly_score(summaries):\n",
    "    \"\"\"Assign anomaly scores to each summary using LLM based on predefined behavior patterns.\"\"\"\n",
    "    scores = []\n",
    "\n",
    "    for summary in summaries:\n",
    "        # Create a prompt for each summary\n",
    "        prompt = (\n",
    "            \"Analyze the following description of customer behavior at a self-checkout station in a shopping mall for potential indicators of theft. \"\n",
    "            \"Consider known theft techniques, such as skip-scanning, barcode switching, weight manipulation, refund fraud, or collusion. \"\n",
    "            f\"Provide a numeric rating between 0 and 1 (0 = normal, 1 = highly anomalous) and explain why you gave this rating. Scene Description: {summary}\"\n",
    "        )\n",
    "\n",
    "        # Encode the prompt for the T5 model\n",
    "        inputs = llm_tokenizer(prompt, return_tensors=\"pt\").to(device)\n",
    "\n",
    "        # Generate a response from the model\n",
    "        output = llm_model.generate(\n",
    "            **inputs,\n",
    "            max_length=200,  # Ensure the model doesn't generate overly long outputs\n",
    "            eos_token_id=llm_tokenizer.eos_token_id,\n",
    "        )\n",
    "\n",
    "        # Decode the response\n",
    "        response = llm_tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "\n",
    "        # Extract the numeric score from the response\n",
    "        try:\n",
    "            # Look for the numeric value in the response\n",
    "            score = float(next((word for word in response.split() if word.replace('.', '', 1).isdigit()), \"0.5\"))\n",
    "        except ValueError:\n",
    "            score = 0.5  # Default score if parsing fails\n",
    "\n",
    "        # Append the score to the list\n",
    "        scores.append(score)\n",
    "\n",
    "    return scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "6f1d4533-c38b-4857-bdb3-e22d58ac2a02",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores  = anomaly_score(summaries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "459e400f-3c1d-4ad7-a045-aba102124041",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "900152d2-f7e1-43c1-93ef-424962f96130",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Analyze the following description of customer behavior at a self-checkout station in a shopping mall for potential indicators of theft. Consider known theft techniques, such as skip-scanning, barcode switching, weight manipulation, refund fraud, or collusion. Provide a numeric rating between 0 and 1 (0 = normal, 1 = highly anomalous) and explain why you gave this rating. Scene Description: In the image, a man is standing in a store aisle, looking at a display of potted plants. He is holding a potted plant in his hand, possibly looking for a suitable plant to purchase. There are several potted plants on the shelf, with some closer to the man and others further away. The man appears to be focused on the plants, possibly considering which one to purchase or looking for inspiration.'"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "a3e07551-e142-4bab-b866-4ef5d2025276",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_anomoly(scores, threshold=0.6):\n",
    "    # Check if any frame has a score above the threshold\n",
    "    is_anomalous = any(score >= threshold for score in scores)\n",
    "\n",
    "    # Return \"Yes\" if any anomaly is detected, otherwise \"No\"\n",
    "    return \"Yes\" if is_anomalous else \"No\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "f84426fd-cb24-4a1b-adfd-aa88edf32296",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'No'"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "is_anomoly(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e1dffff-7186-43a6-8aa0-4d57142a526f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
