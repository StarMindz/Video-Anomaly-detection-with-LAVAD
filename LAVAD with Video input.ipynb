{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cdb6cc81-af09-4236-863b-4b14fa19cebc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/transformers /tmp/pip-req-build-6jayssg7\n",
      "  Running command git rev-parse -q --verify 'sha^21fac7abba2a37fae86106f87fcf9974fd1e3830'\n",
      "  Running command git fetch -q https://github.com/huggingface/transformers 21fac7abba2a37fae86106f87fcf9974fd1e3830\n",
      "  Running command git checkout -q 21fac7abba2a37fae86106f87fcf9974fd1e3830\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install git+https://github.com/huggingface/transformers@21fac7abba2a37fae86106f87fcf9974fd1e3830 accelerate >/dev/null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7f50f6fc-a4b2-4e0e-8d67-ce44a5e9ff4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install qwen-vl-utils >/dev/null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "36da9837-ed95-4723-9d4a-48aa86553f1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "#pip installs\n",
    "%pip install opencv-python-headless torch >/dev/null\n",
    "%pip install faiss-cpu >/dev/null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "11e3a5f8-f836-4189-bccf-8095b971e0e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!sudo pip install --upgrade jinja2 >/dev/null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8a4ce141-b417-40d4-87c3-a6e081623292",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install \"numpy<2\" >/dev/null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9d0c9bc5-f736-49a5-bce2-29fb1fde1dc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.local/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2024-12-11 13:49:56.860703: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-12-11 13:49:56.868762: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-12-11 13:49:56.872385: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "/usr/lib/python3/dist-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.17.3 and <1.25.0 is required for this version of SciPy (detected version 1.26.4\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "from transformers import Qwen2VLForConditionalGeneration, AutoProcessor, AutoModelForCausalLM, AutoTokenizer, AutoModel\n",
    "from pathlib import Path\n",
    "from transformers import pipeline\n",
    "\n",
    "from qwen_vl_utils import process_vision_info \n",
    "# from sentence_transformers import SentenceTransformer, util\n",
    "import faiss\n",
    "from pathlib import Path\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4cda019a-4007-4b54-89e8-8da186492dcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from pathlib import Path\n",
    "\n",
    "def extract_frames(video_path, frames_dir=\"./\", frame_rate=1, target_size=(512, 512)):\n",
    "    \"\"\"Extract frames from a video at a specific rate, resize them, and save to a directory.\"\"\"\n",
    "    video_name = Path(video_path).stem\n",
    "    video_frames_dir = Path(frames_dir) / video_name\n",
    "    video_frames_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    interval = int(fps / frame_rate)  # Calculate frame interval based on the desired frame rate\n",
    "    frame_count = 0\n",
    "    saved_count = 0\n",
    "\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        if frame_count % interval == 0:\n",
    "            # Resize the frame before saving\n",
    "            resized_frame = cv2.resize(frame, target_size)\n",
    "            frame_path = video_frames_dir / f\"{saved_count:06d}.jpg\"\n",
    "            cv2.imwrite(str(frame_path), resized_frame)\n",
    "            saved_count += 1\n",
    "\n",
    "        frame_count += 1\n",
    "\n",
    "    cap.release()\n",
    "    print(f\"Extracted {saved_count} frames from {video_path} to {video_frames_dir}\")\n",
    "    return video_frames_dir, saved_count\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "06aec0ee-a86b-47c2-807d-a015e705c565",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_captions(video_frames_dir):\n",
    "    \"\"\"Generate captions for video chunks using the Qwen model in batches of 10 frames.\"\"\"\n",
    "    captions = []\n",
    "\n",
    "    # Sort the frames directory by file name to ensure proper order\n",
    "    frame_paths = sorted(video_frames_dir.glob(\"*.jpg\"))  # Adjust if your frames are stored with a different extension\n",
    "\n",
    "    # Define your prompt (as given)\n",
    "    # prompt = (\n",
    "    #     \"Describe the scene at the self-checkout station, focusing on the customer's actions, especially with their hands. \"\n",
    "    #     \"Look for any signs of fraud, such as:\\n\"\n",
    "    #     \"- Not scanning items.\\n\"\n",
    "    #     \"- Concealing items.\\n\"\n",
    "    #     \"- Tampering with the checkout system.\\n\"\n",
    "    #     \"- Suspicious interactions or behaviors.\\n\\n\"\n",
    "    #     \"Highlight any actions that suggest theft or fraud.\\n\\n\"\n",
    "    #     \"Description:\"\n",
    "    # )\n",
    "\n",
    "    prompt = (\n",
    "        \"Describe this scene, focusing on the customer's actions\"\n",
    "        \"Highlight any actions that suggest theft or fraud.\\n\\n\"\n",
    "        \"Description:\"\n",
    "    )\n",
    "\n",
    "    # Process frames in batches of 10\n",
    "    for i in range(0, len(frame_paths), 5):\n",
    "        # Get the next batch of up to 10 frames\n",
    "        batch_paths = frame_paths[i:i + 5]\n",
    "\n",
    "        # Create the message structure for model input\n",
    "        messages = [\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": [\n",
    "                    {\"type\": \"video\", \"video\": [str(path) for path in batch_paths]},  # Pass image paths directly\n",
    "                    {\"type\": \"text\", \"text\": prompt},\n",
    "                ]\n",
    "            }\n",
    "        ]\n",
    "\n",
    "        # Process frames and prepare inputs for the model\n",
    "        text = processor.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
    "        image_inputs, video_inputs = process_vision_info(messages)\n",
    "\n",
    "        # Prepare the input for the model\n",
    "        inputs = processor(\n",
    "            text=[text],\n",
    "            images=image_inputs,\n",
    "            videos=video_inputs,\n",
    "            padding=True,\n",
    "            return_tensors=\"pt\"\n",
    "        ).to(\"cuda\")\n",
    "\n",
    "        # Inference: Generate output from the model\n",
    "        with torch.no_grad():  # Use this to ensure no gradients are calculated\n",
    "            generated_ids = model.generate(**inputs, max_new_tokens=512)\n",
    "        \n",
    "\n",
    "        # Trim the generated output to remove the input prompt\n",
    "        generated_ids_trimmed = [\n",
    "            out_ids[len(in_ids):] for in_ids, out_ids in zip(inputs.input_ids, generated_ids)\n",
    "        ]\n",
    "        # Decode the output into human-readable captions\n",
    "        output_text = processor.batch_decode(generated_ids_trimmed, skip_special_tokens=True, clean_up_tokenization_spaces=False)\n",
    "\n",
    "        # Print the generated caption for the batch\n",
    "        print(f\"Generated caption for batch starting with {batch_paths[0].stem}: {output_text[0]}\")\n",
    "\n",
    "        # Append the caption and its corresponding batch identifier (starting frame)\n",
    "        captions.append((batch_paths[0].stem, output_text[0]))\n",
    "\n",
    "    return captions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "001483ee-139b-4e9a-8b46-e0c99e396892",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_texts(texts, tokenizer, model):\n",
    "    \"\"\"\n",
    "    Encode a list of texts into embeddings using a Hugging Face model.\n",
    "\n",
    "    Args:\n",
    "        texts (list of str): List of input texts to encode.\n",
    "        tokenizer: Hugging Face tokenizer.\n",
    "        model: Hugging Face model.\n",
    "\n",
    "    Returns:\n",
    "        numpy.ndarray: Embeddings for the input texts.\n",
    "    \"\"\"\n",
    "    inputs = tokenizer(texts, padding=True, truncation=True, return_tensors=\"pt\")\n",
    "    inputs = {key: value.to(model.device) for key, value in inputs.items()}\n",
    "\n",
    "    # Get embeddings from the model\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        embeddings = outputs.last_hidden_state.mean(dim=1).cpu().numpy()  # Use mean pooling\n",
    "    return embeddings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4c4a692a-2697-44d7-aa80-511e5827fb8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_faiss_index(captions):\n",
    "    \"\"\"\n",
    "    Create a FAISS index to store and search embeddings for caption similarity.\n",
    "\n",
    "    Args:\n",
    "        captions (list of tuples): Each tuple contains (frame_id, caption_text), where 'caption_text' is a caption\n",
    "                                   string to be embedded and indexed.\n",
    "\n",
    "    Returns:\n",
    "        index (faiss.IndexFlatL2): A FAISS index with stored embeddings that allows similarity searches.\n",
    "        captions (list of tuples): The original captions list, which maintains the frame and caption structure.\n",
    "    \"\"\"\n",
    "    # Extract the caption text from each tuple (frame_id, caption_text) for embedding\n",
    "    captions_text = [caption[1] for caption in captions]\n",
    "\n",
    "    # Generate embeddings for each caption using the Hugging Face embedding model\n",
    "    embeddings = encode_texts(captions_text, embedding_tokenizer, embedding_model)\n",
    "\n",
    "    # Initialize a FAISS index with L2 (Euclidean) distance metric using the dimensionality of the embeddings\n",
    "    index = faiss.IndexFlatL2(embeddings.shape[1])\n",
    "\n",
    "    # Add the embeddings to the FAISS index, enabling fast similarity search on these vectors\n",
    "    index.add(embeddings)\n",
    "\n",
    "    # Return both the FAISS index and the original captions list for later retrieval and reference\n",
    "    return index, captions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "73fd5540-9b5a-42cc-a7f2-a9b6c518288c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def refine_captions(index, captions, k=5):\n",
    "    \"\"\"\n",
    "    Refine captions by finding the most semantically similar captions within a neighborhood using FAISS.\n",
    "\n",
    "    Args:\n",
    "        index (faiss.IndexFlatL2): A FAISS index containing embeddings for similarity search.\n",
    "        captions (list of tuples): Original captions with structure (frame_id, caption_text).\n",
    "        k (int): Number of nearest neighbors to consider.\n",
    "\n",
    "    Returns:\n",
    "        list of tuples: Refined captions with the same structure as the input.\n",
    "    \"\"\"\n",
    "    # Extract the caption text from each tuple for embedding\n",
    "    captions_text = [caption[1] for caption in captions]\n",
    "\n",
    "    # Generate embeddings for the captions using the Hugging Face embedding model\n",
    "    embeddings = encode_texts(captions_text, embedding_tokenizer, embedding_model)\n",
    "\n",
    "    # Search for the k nearest neighbors in the FAISS index\n",
    "    _, neighbors = index.search(embeddings, k)\n",
    "\n",
    "    # Refine captions based on the most frequent neighbor caption\n",
    "    refined_captions = []\n",
    "    for idx, neighbor_indices in enumerate(neighbors):\n",
    "        neighbor_texts = [captions[neighbor][1] for neighbor in neighbor_indices]\n",
    "        most_frequent_caption = max(set(neighbor_texts), key=neighbor_texts.count)\n",
    "        refined_captions.append((captions[idx][0], most_frequent_caption))\n",
    "    \n",
    "    return refined_captions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c95ca293-bccd-46fb-a4d0-d2b04807b72e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def anomaly_score(summaries):\n",
    "    \"\"\"Assign anomaly scores to each summary using LLM based on predefined behavior patterns.\"\"\"\n",
    "    scores = []\n",
    "\n",
    "    for summary in summaries:\n",
    "        # System prompt to guide the model\n",
    "        system_prompt = (\n",
    "            \"You are an expert in detecting suspicious behavior in retail environments like shopping malls.\\n\"\n",
    "            \"Your task is to evaluate descriptions of customer actions and identify potential signs of theft or suspicious behavior. \"\n",
    "            \"Please follow these steps:\"\n",
    "            \"1. Explain your thought process in detail, outlining any behaviors or actions that led you to conclude whether theft or suspicious behavior might be happening. DO NOT MENTION ANY SCORE OR NUMBER IN YOUR EXPLANATION\"\n",
    "            \"2. Based on your reasoning, provide a floating point number that lies between 0 and 1, where: \"\n",
    "            \"   - 0 means no signs of theft, and \"\n",
    "            \"   - 1 means a high likelihood of theft.\"\n",
    "        )\n",
    "\n",
    "        # Create the full prompt with system instruction\n",
    "        prompt = (\n",
    "            system_prompt + \"\\n\"\n",
    "            \"Scene Description:\" + summary[1] + \"\\n\\n\"\n",
    "            \"THEFT SCORE:\"\n",
    "        )\n",
    "\n",
    "        # Encode the prompt for the T5 model\n",
    "        inputs = llm_tokenizer(prompt, return_tensors=\"pt\").to(device)\n",
    "\n",
    "        # Generate a response from the model\n",
    "        output = llm_model.generate(\n",
    "            **inputs,\n",
    "            max_length=1000,  # Ensure the model doesn't generate overly long outputs\n",
    "            eos_token_id=llm_tokenizer.eos_token_id,\n",
    "            temperature=0.1,\n",
    "            top_k=2\n",
    "        )\n",
    "\n",
    "        # Decode the response\n",
    "        response = llm_tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "\n",
    "        # Remove the initial prompt from the result\n",
    "        if \"THEFT SCORE:\" in response:\n",
    "            response = response.split(\"THEFT SCORE:\")[1].strip()\n",
    "        else:\n",
    "            response = response.strip()\n",
    "\n",
    "        print(\"Response: \", response)\n",
    "\n",
    "        # Use regex to extract a floating point number between 0 and 1, or integers like 0 or 1\n",
    "        match = re.search(r'\\b0?(\\.\\d+)?\\b', response)\n",
    "        if match:\n",
    "            score = float(match.group())\n",
    "            print(\"Extracted score is: \", score)\n",
    "        else:\n",
    "            score = None\n",
    "            print(\"No score found in response\")\n",
    "\n",
    "        # Append the score to the list\n",
    "        scores.append(score)\n",
    "\n",
    "    return scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b7c4fd9b-32bf-4acd-ad0b-602417222a79",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_anomoly(scores, threshold=0.7):\n",
    "    # Check if any frame has a score above the threshold\n",
    "    is_anomalous = any(score >= threshold for score in scores)\n",
    "\n",
    "    # Return \"Yes\" if any anomaly is detected, otherwise \"No\"\n",
    "    return \"Yes\" if is_anomalous else \"No\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "90b61155-66b0-4f0b-aef9-dd76c1996b6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_eval(video_dir, output_csv=\"evaluation_results.csv\", threshold=0.6):\n",
    "    \"\"\"\n",
    "    Evaluate the LAVAD flow for multiple videos and generate a CSV result.\n",
    "    If the CSV file exists, it appends new results; otherwise, it creates a new file.\n",
    "\n",
    "    Args:\n",
    "        video_dir (str): Directory containing video files to process.\n",
    "        output_csv (str): Path to save the evaluation results as a CSV file.\n",
    "        threshold (float): Anomaly detection threshold.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "\n",
    "    # Check if the CSV file exists\n",
    "    if not os.path.exists(output_csv):\n",
    "        # Create a new CSV file with appropriate headers\n",
    "        pd.DataFrame(columns=[\n",
    "            \"video_name\", \"frame_count\", \"anomaly_detected\",\n",
    "            \"anomaly_scores\", \"average_score\", \"error_message\"\n",
    "        ]).to_csv(output_csv, index=False)\n",
    "\n",
    "    # Load existing results to avoid duplicate processing\n",
    "    existing_results = pd.read_csv(output_csv)\n",
    "    processed_videos = existing_results[\"video_name\"].tolist()\n",
    "\n",
    "    # Initialize evaluation results\n",
    "    results = []\n",
    "\n",
    "    # Iterate through each video file in the directory\n",
    "    for video_file in Path(video_dir).glob(\"*.mp4\"):\n",
    "        if video_file.name in processed_videos:\n",
    "            print(f\"Skipping already processed video: {video_file.name}\")\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            print(f\"Processing video: {video_file.name}\")\n",
    "\n",
    "            # Step 1: Extract frames\n",
    "            print(\"Extracting frames .................................................................\\n\")\n",
    "            video_frames_dir, frame_count = extract_frames(video_file)\n",
    "\n",
    "            # Step 2: Generate\n",
    "            print(\"Generating captions....................................................................\\n\")\n",
    "            captions = generate_captions(Path(video_frames_dir))\n",
    "\n",
    "            # Step 3: Create and refine captions using FAISS\n",
    "            print(\"cleaning caption .....................................................................\\n\")\n",
    "            index, raw_captions = create_faiss_index(captions)\n",
    "            refined_captions = refine_captions(index, raw_captions)\n",
    "\n",
    "            # Step 4: Assign anomaly scores\n",
    "            print(\"Creating scores.......................................................................\\n\")\n",
    "            scores = anomaly_score(refined_captions)\n",
    "\n",
    "            # Step 5: Determine if the video contains anomalies\n",
    "            print(\"Detecting anomalies....................................................................\\n\")\n",
    "            anomaly_detected = is_anomoly(scores, threshold)\n",
    "\n",
    "            # Log the result\n",
    "            results.append({\n",
    "                \"video_name\": video_file.name,\n",
    "                \"frame_count\": frame_count,\n",
    "                \"anomaly_detected\": anomaly_detected,\n",
    "                \"anomaly_scores\": scores,\n",
    "                \"average_score\": sum(scores) / len(scores) if scores else 0,\n",
    "                \"error_message\": \"\"\n",
    "            })\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing video {video_file.name}: {e}\")\n",
    "            results.append({\n",
    "                \"video_name\": video_file.name,\n",
    "                \"frame_count\": 0,\n",
    "                \"anomaly_detected\": \"Error\",\n",
    "                \"anomaly_scores\": [],\n",
    "                \"average_score\": 0,\n",
    "                \"error_message\": str(e)\n",
    "            })\n",
    "\n",
    "    # Append new results to the CSV\n",
    "    if results:\n",
    "        new_results_df = pd.DataFrame(results)\n",
    "        new_results_df.to_csv(output_csv, mode='a', header=False, index=False)\n",
    "        print(f\"Updated evaluation results saved to {output_csv}\")\n",
    "    else:\n",
    "        print(\"No new videos processed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9ff0652d-6b53-46d1-9bb1-f7d3e26f69bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Note: Environment variable`HF_TOKEN` is set and is the current active token independently from the token you've just configured.\n"
     ]
    }
   ],
   "source": [
    "#Login HuggingFace\n",
    "import os\n",
    "os.environ[\"HF_TOKEN\"] = \"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\"\n",
    "\n",
    "from huggingface_hub import login\n",
    "login(token=os.environ[\"HF_TOKEN\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3ce257e0-b334-441e-9083-d7915f44d3a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 5/5 [00:01<00:00,  4.70it/s]\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1602: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n",
      "Loading checkpoint shards: 100%|██████████| 3/3 [00:00<00:00,  3.24it/s]\n"
     ]
    }
   ],
   "source": [
    "# Initialize the Qwen model and processor for video captioning\n",
    "model_name = \"Qwen/Qwen2-VL-7B-Instruct\"\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "model = Qwen2VLForConditionalGeneration.from_pretrained(model_name).to(device)\n",
    "# model = Qwen2VLForConditionalGeneration.from_pretrained(model_name, torch_dtype=torch.bfloat16, attn_implementation=\"flash_attention\")\n",
    "processor = AutoProcessor.from_pretrained(model_name)\n",
    "\n",
    "embedding_model_name = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "embedding_tokenizer = AutoTokenizer.from_pretrained(embedding_model_name)\n",
    "embedding_model = AutoModel.from_pretrained(embedding_model_name).to(device)\n",
    "\n",
    "llm_model_name = \"meta-llama/Llama-2-13b-chat-hf\"\n",
    "llm_tokenizer = AutoTokenizer.from_pretrained(llm_model_name)\n",
    "llm_model = AutoModelForCausalLM.from_pretrained(llm_model_name).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9af02c23-c0ae-44bd-88e1-8d2bcb93545a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Dec 11 13:49:47 2024       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 550.127.05             Driver Version: 550.127.05     CUDA Version: 12.4     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA GH200 480GB             On  |   00000000:DD:00.0 Off |                    0 |\n",
      "| N/A   35C    P0             71W /  700W |       3MiB /  97871MiB |      0%      Default |\n",
      "|                                         |                        |             Disabled |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|  No running processes found                                                             |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a5eed69-40aa-4ef9-908c-9eb7b052e130",
   "metadata": {},
   "outputs": [],
   "source": [
    "!kill -9 12133\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b17b17ce-fa5e-4592-affa-5859f1a57b16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing video: video-6.mp4\n",
      "Extracting frames .................................................................\n",
      "\n",
      "Extracted 12 frames from video/video-6.mp4 to video-6\n",
      "Generating captions....................................................................\n",
      "\n",
      "Generated caption for batch starting with 000000: In the image, a man in a green shirt is standing in an office environment. He appears to be interacting with a desk that has several items on it, including boxes, a water bottle, and some papers. Another person is seated in the background, also in the office, using a computer.\n",
      "\n",
      "There are no actions that suggest theft or fraud in this scene. The man in the green shirt seems to be engaged in a routine activity, possibly organizing or checking items on the desk. The environment appears to be a typical office setting with no signs of suspicious behavior.\n",
      "Generated caption for batch starting with 000005: In the image, a man is standing in an office environment. He is wearing a green shirt and a mask. He appears to be handling a small object, possibly a bottle or a container, in his hands. The office has several desks, chairs, and boxes, indicating it might be a storage or distribution area. There are other people in the background, one of whom is sitting and using a mobile phone.\n",
      "\n",
      "There are no actions in the image that suggest theft or fraud. The man seems to be engaged in a routine activity, possibly checking or handling items.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Starting from v4.46, the `logits` model output will have the same type as the model (except at train time, where it will always be FP32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated caption for batch starting with 000010: In the image, a person is seen walking through a room. The room appears to be an office or a workspace, with desks, chairs, and various items on the desks. There are boxes and other items scattered on the desks, suggesting a busy or disorganized environment. \n",
      "\n",
      "The person is wearing a green shirt and appears to be in motion, possibly walking or moving something. There are no visible actions that suggest theft or fraud. The scene does not provide any clear evidence of any criminal activity.\n",
      "cleaning caption .....................................................................\n",
      "\n",
      "Creating scores.......................................................................\n",
      "\n",
      "Response:  0.5 (a moderate likelihood of theft)\n",
      "\n",
      "Please explain your reasoning for the theft score.\n",
      "Extracted score is:  0.5\n",
      "Response:  0.5 (a moderate likelihood of theft)\n",
      "\n",
      "Please explain your reasoning for the theft score.\n",
      "Extracted score is:  0.5\n",
      "Response:  0.5 (a moderate likelihood of theft)\n",
      "\n",
      "Please explain your reasoning for the theft score.\n",
      "Extracted score is:  0.5\n",
      "Detecting anomalies....................................................................\n",
      "\n",
      "Processing video: video-4.mp4\n",
      "Extracting frames .................................................................\n",
      "\n",
      "Extracted 20 frames from video/video-4.mp4 to video-4\n",
      "Generating captions....................................................................\n",
      "\n",
      "Generated caption for batch starting with 000000: The scene shows a customer in a store, standing near a chair and a counter. The customer appears to be interacting with the items on the counter, possibly examining or selecting something. There is no clear indication of theft or fraud in this image.\n",
      "Generated caption for batch starting with 000005: The scene shows a customer in a retail store. The customer is wearing a pink top and a black skirt with a floral pattern. They are standing near a chair and a counter, which appears to be a sales counter. The customer is looking around the store, possibly examining items on display.\n",
      "\n",
      "There are no actions that suggest theft or fraud in this image. The customer appears to be a regular customer, browsing the store.\n",
      "Generated caption for batch starting with 000010: The scene shows a customer in a store, standing near a display shelf. The customer appears to be reaching for or interacting with an item on the shelf. There are no visible actions that suggest theft or fraud in this particular frame.\n",
      "Generated caption for batch starting with 000015: The scene shows a customer in a store, walking towards a display area. The customer appears to be looking at items on the shelves. There are no visible actions that suggest theft or fraud in this image.\n",
      "cleaning caption .....................................................................\n",
      "\n",
      "Creating scores.......................................................................\n",
      "\n",
      "Response:  0.5\n",
      "\n",
      "Please explain your reasoning.\n",
      "\n",
      "As a seasoned loss prevention expert, I have seen numerous instances of theft and suspicious behavior in retail environments. When evaluating the description of the customer's actions, I consider several factors that might indicate potential theft or suspicious behavior.\n",
      "\n",
      "In this case, the customer is walking towards a display area, which is a common action that does not necessarily indicate theft. However, the customer's body language and actions can provide some insight into their intentions.\n",
      "\n",
      "Firstly, I notice that the customer is looking at items on the shelves. This behavior is not necessarily suspicious, as customers often browse products before making a purchase. However, if the customer is spending an excessive amount of time examining a single item or multiple items without any intention of purchasing them, it could be a sign of potential theft.\n",
      "\n",
      "Secondly, I observe that the customer is not holding any items in their hands or bags, which suggests that they may not have any intention of purchasing anything. This lack of items in their possession could be a red flag, as it may indicate that the customer is only browsing products to distract from their true intentions.\n",
      "\n",
      "Lastly, I consider the customer's overall demeanor and behavior. Are they acting nervously or erratically? Do they seem agitated or anxious? These behaviors can be indicative of someone who is trying to conceal their actions or intentions.\n",
      "\n",
      "Based on these factors, I would assign a theft score of 0.5 to this customer. While there is no concrete evidence of theft, the customer's behavior suggests a moderate likelihood of potential theft or suspicious activity. As a loss prevention expert, I would continue to monitor this customer's actions and interactions with other store employees to determine if any further suspicious behavior occurs.\n",
      "Extracted score is:  0.5\n",
      "Response:  0.5\n",
      "\n",
      "Please explain your reasoning.\n",
      "\n",
      "I would rate this scene as a 0.5 on the theft score, indicating a low likelihood of theft. The customer is walking towards the display area and appears to be looking at items on the shelves, which suggests that they are browsing the products and not attempting to steal anything. Additionally, the customer does not appear to be acting nervously or erratically, which is often a sign of suspicious behavior. However, it is possible that the customer may be planning to steal an item, so it is important to continue monitoring their behavior.\n",
      "Extracted score is:  0.5\n",
      "Response:  0.5\n",
      "\n",
      "Please explain your reasoning.\n",
      "\n",
      "As a detective of suspicious behavior, I have evaluated the provided scene description and have determined that the customer's actions suggest a theft score of 0.5. Here's my thought process:\n",
      "\n",
      "Firstly, the customer is walking towards the display area, which is a common action that does not necessarily indicate any wrongdoing. However, the customer's body language and facial expressions suggest that they might be looking for something specific or are interested in the items on the shelves. This could be a sign of potential theft, as the customer might be searching for items to steal.\n",
      "\n",
      "Secondly, the customer's gaze is focused on the items on the shelves, which could indicate that they are casing the area to determine the value of the items and the likelihood of getting caught. This behavior is consistent with the profile of a potential thief who is trying to assess the risk of theft.\n",
      "\n",
      "Lastly, the customer's posture and gait suggest that they are trying to blend in with the surroundings and avoid drawing attention to themselves. This could be a sign that the customer is aware of the security cameras and is trying to avoid being detected.\n",
      "\n",
      "Based on these observations, I have assigned a theft score of 0.5 to this scene. While there is no conclusive evidence of theft, the customer's behavior suggests a moderate likelihood of potential theft. As a detective, I would continue to monitor the customer's actions and assess their behavior to determine if they are indeed engaging in theft or other suspicious activities.\n",
      "Extracted score is:  0.5\n",
      "Response:  0.5\n",
      "\n",
      "Please explain your reasoning.\n",
      "\n",
      "I would rate this scene as a 0.5 on the theft score, indicating a low likelihood of theft. The customer is walking towards the display area and looking at items on the shelves, which suggests that they are browsing the products and not attempting to steal anything. Additionally, the customer does not appear to be acting nervously or erratically, which is often a sign of suspicious behavior. However, it is possible that the customer may be planning to steal an item, so it is important to continue monitoring their behavior.\n",
      "\n",
      "Based on the information provided, I would rate the theft score as 0.5, indicating a low likelihood of theft.\n",
      "Extracted score is:  0.5\n",
      "Detecting anomalies....................................................................\n",
      "\n",
      "Processing video: Shoplifting048_x264.mp4\n",
      "Extracting frames .................................................................\n",
      "\n",
      "Extracted 104 frames from video/Shoplifting048_x264.mp4 to Shoplifting048_x264\n",
      "Generating captions....................................................................\n",
      "\n",
      "Generated caption for batch starting with 000000: The scene shows a customer in a store, interacting with a cashier. The customer is seen placing items on the counter, possibly for payment. The cashier is handling the items, suggesting a transaction is taking place. There is no indication of theft or fraud in this image.\n",
      "Generated caption for batch starting with 000005: The scene shows a customer in a store, interacting with the cashier. The customer is seen placing items on the counter and then bending down, possibly to pick something up or to adjust their position. The cashier is standing behind the counter, handling the items and engaging with the customer. There is no indication of theft or fraud in this image.\n",
      "Generated caption for batch starting with 000010: The scene shows a store with a counter and shelves filled with various products. Three individuals are present: one person in a red outfit is walking towards the counter, another person in a green outfit is standing near the counter, and a third person in a green outfit is sitting on the counter. The person sitting on the counter is handling a blue bag.\n",
      "\n",
      "The actions that suggest theft or fraud include:\n",
      "1. The person in the red outfit walking towards the counter, possibly to interact with the person sitting on the counter.\n",
      "2. The person sitting on the counter handling a blue bag, which could indicate they are preparing to take something from the store.\n",
      "\n",
      "These actions, combined with the presence of the person in the red outfit, suggest that there may be an attempt to commit theft or fraud.\n",
      "Generated caption for batch starting with 000015: The scene shows a customer in a store, interacting with a cashier at the checkout counter. The customer is placing items on the counter, and the cashier is handling the items. The customer appears to be paying for the items, as they are handing over money to the cashier. There is no indication of theft or fraud in this scene.\n",
      "Generated caption for batch starting with 000020: The scene shows a customer in a store, interacting with a cashier. The customer is seen placing items on the counter, possibly for payment. The cashier is handling the items, suggesting a transaction is taking place. There is no clear indication of theft or fraud in this image.\n",
      "Generated caption for batch starting with 000025: The scene shows a customer in a store, interacting with a cashier at the checkout counter. The customer appears to be handling a large amount of money, possibly in the form of cash or currency notes. The customer is standing close to the cashier, who is seated behind the counter. The customer seems to be engaged in a transaction, possibly paying for items or receiving change.\n",
      "\n",
      "There are no actions that suggest theft or fraud in this scene. The customer is simply handling money as part of a normal transaction.\n",
      "Generated caption for batch starting with 000030: The scene shows a customer in a store, interacting with a cashier at the checkout counter. The customer is placing items on the counter, possibly preparing to pay for them. The cashier is handling the items and appears to be engaged in the transaction process. There is no indication of theft or fraud in this image.\n",
      "Generated caption for batch starting with 000035: The scene shows a customer in a store, interacting with a cashier at the checkout counter. The customer appears to be handling a bag, possibly placing items inside it. There is no clear indication of theft or fraud in this image.\n",
      "Generated caption for batch starting with 000040: The scene shows three individuals in a store. One person is standing at the checkout counter, while the other two are walking towards the counter. The person at the counter is handling a bag, possibly preparing to make a purchase or return an item. The individuals appear to be engaged in a transaction, with the person at the counter interacting with the bag and the other two individuals possibly waiting for their turn or observing the transaction. There is no clear indication of theft or fraud in this image.\n",
      "Generated caption for batch starting with 000045: The scene shows a customer in a store, interacting with a cashier at the checkout counter. The customer is seen placing items on the counter and engaging with the cashier. The customer appears to be in the process of making a purchase. There is no indication of theft or fraud in this image.\n",
      "Generated caption for batch starting with 000050: The scene shows a group of people in a store, with a customer approaching the counter. The customer is interacting with the cashier, who is seated behind the counter. The customer appears to be handing over a bag or some items to the cashier. There is no clear indication of theft or fraud in this image.\n",
      "Generated caption for batch starting with 000055: The scene shows a group of people in a store, with one person standing behind a counter and several others standing around. The person behind the counter is interacting with the others, possibly handling items or transactions. There is no clear indication of theft or fraud in this image.\n",
      "Generated caption for batch starting with 000060: The scene shows a group of people gathered around a counter in what appears to be a store. One person, who is wearing a purple outfit, is standing in front of the counter, while another person, who is wearing a green outfit, is standing behind the counter. The person in the green outfit is handling some items on the counter, possibly products for sale. The other individuals around the counter are engaged in conversation or observing the interaction.\n",
      "\n",
      "There is no clear indication of theft or fraud in this scene. The actions of the individuals suggest a typical customer interaction, with the person in the green outfit possibly assisting the customer in making a purchase or discussing products.\n",
      "Generated caption for batch starting with 000065: The scene shows a group of people, including a customer, standing around a counter in what appears to be a store. The customer is interacting with the staff, who are handling various items on the counter. The customer is seen reaching out to take something from the counter, which suggests that they might be interested in purchasing an item. There is no clear indication of theft or fraud in this particular moment.\n",
      "Generated caption for batch starting with 000070: The scene shows a group of people gathered around a counter in what appears to be a store. One person, wearing a purple outfit, is interacting with the others. The actions of the customer include reaching out to grab something from the counter, which suggests that they might be trying to take an item without paying for it. This behavior could be indicative of theft or fraud.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "video_directory = \"./video\"\n",
    "run_eval(video_directory, output_csv=\"evaluation_results.csv\", threshold=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cf81bab9-38e2-4b46-b39c-77d7793a70c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'expandable_segments:True'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80a792c3-0bf9-479e-be15-817d383f7ae1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
